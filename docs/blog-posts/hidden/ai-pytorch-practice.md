---
title: Th·ª±c h√†nh Deep Learning v·ªõi PyTorch
---

# Th·ª±c h√†nh Deep Learning v·ªõi PyTorch

![PyTorch](./images/ai-pytorch.png)

Sau khi t√¨m hi·ªÉu l√Ω thuy·∫øt n·ªÅn t·∫£ng AI v√† PyTorch, b∆∞·ªõc ti·∫øp theo l√† l√†m b√†i to√°n ·ª©ng d·ª•ng th·ª±c t·∫ø.

Tuy nhi√™n, ch√∫ng ta v·∫´n s·∫Ω gi·ªØ ƒë√∫ng h∆∞·ªõng ƒëi ban ƒë·∫ßu l√† kh√¥ng thu·∫ßn nghi√™n c·ª©u, m√† l√† x√¢y h·ªá th·ªëng AI d√πng ƒë∆∞·ª£c.

[1. Setup m√¥i tr∆∞·ªùng PyTorch](#1)

[2. B√†i to√°n D·ª± ƒëo√°n gi√° nh√†](#2)

[3. B√†i to√°n Giao d·ªãch b√¨nh th∆∞·ªùng / b·∫•t th∆∞·ªùng](#3)

<!-- [1. Setup m√¥i tr∆∞·ªùng PyTorch](#1)

[2. Image classification - Ph√¢n lo·∫°i ·∫£nh](#2)

[3. Object detection ‚Äì Ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng](#3)

[4. Segmentation](#4)

[5. Pose estimation - D·ª± ƒëo√°n t∆∞ th·∫ø](#5)

[6. Image generation ‚Äì T·∫°o ·∫£nh](#6)

[7. Anomaly Detection & Ph√°t hi·ªán ƒëi·ªÉm b·∫•t th∆∞·ªùng](#7)

[8. Sentiment analysis - Ph√¢n t√≠ch c·∫£m x√∫c](#8)

[9. Video classification - Ph√¢n lo·∫°i video](#9) -->

<a name="1"></a>

## üìå 1. Setup m√¥i tr∆∞·ªùng PyTorch

- ‚ùå D√πng Google Colab hay Jupyter local ch·ªâ ph√π h·ª£p cho l√∫c h·ªçc PyTorch, test, demo & research, hay khi c·∫ßn GPU t·∫°m m√† m√°y local kh√¥ng c√≥.

- ‚úîÔ∏è Recommend m·ªçi ng∆∞·ªùi d√πng VS Code + venv (m√¥i tr∆∞·ªùng ·∫£o) lu√¥n b·ªüi:
  - ‚úß Gi·ªëng m√¥i tr∆∞·ªùng th·ª±c t·∫ø
  - ‚úß D·ªÖ deploy
  - ‚úß D·ªÖ ƒë√≥ng g√≥i .exe
  - ‚úß D·ªÖ debug
  - ‚úß Qu·∫£n l√Ω code r√µ r√†ng

### ‚öôÔ∏è Setup

- ‚ù∂ C√†i Python ch√≠nh th·ª©c

- ‚ù∑ T·∫°o folder project

- ‚ù∏ T·∫°o m√¥i tr∆∞·ªùng ·∫£o

  ```bash
  python -m venv venv
  ```

- ‚ùπ Active m√¥i tr∆∞·ªùng ·∫£o

  ```bash
  venv\Scripts\activate
  ```

- ‚ù∫ C√†i PyTorch

  ```bash
  pip install torch torchvision torchaudio
  ```

  - ·ªû ƒë√¢y ch√∫ng ta d√πng CPU l√† ƒë·ªß, ch∆∞a c·∫ßn GPU.

- ‚ùª VS Code setup
  - ‚úß M·ªü project tr√™n VS Code
  - ‚úß Ch·ªçn Python Interpreter ‚Üí venv
  - ‚úß C√†i extension: Python, Pylance

<a name="2"></a>

## üìå 2. B√†i to√°n AI d·ª± ƒëo√°n ƒë∆°n gi·∫£n (Linear Regression)

- B√†i to√°n kinh ƒëi·ªÉn: D·ª± ƒëo√°n gi√° nh√†

### 1Ô∏è‚É£ Ph√¢n t√≠ch b√†i to√°n

- Input: ƒë·∫∑c tr∆∞ng ng√¥i nh√†
- Output: gi√° nh√† (s·ªë th·ª±c)

- üëâ AI s·∫Ω ph·∫£i h·ªçc xu h∆∞·ªõng t·ª´ d·ªØ li·ªáu:
  - **‚ÄúV·ªõi c√°c ƒë·∫∑c tr∆∞ng n√†y, gi√° th∆∞·ªùng n·∫±m ·ªü kho·∫£ng n√†o?‚Äù**

### 2Ô∏è‚É£ D·ªØ li·ªáu gi·∫£ l·∫≠p

- Ch√∫ng ta t·∫°o dataset ƒë∆°n gi·∫£n nh∆∞ng th·ª±c t·∫ø:
  | Feature | √ù nghƒ©a |
  | -------- | --------- |
  | area | Di·ªán t√≠ch (m¬≤) |
  | bedrooms | S·ªë ph√≤ng |
  | distance | Kho·∫£ng c√°ch t·ªõi trung t√¢m (km) |

  - üëâ 3 feature ‚Üí 1 gi√°

### 3Ô∏è‚É£ Structure project

- ```
  house_price/
  ‚îÇ
  ‚îú‚îÄ venv/
  ‚îú‚îÄ data.py          # D·ªØ li·ªáu
  ‚îú‚îÄ model.py         # ƒê·ªãnh nghƒ©a Model
  ‚îú‚îÄ train.py         # H·ªçc
  ‚îú‚îÄ predict.py       # D·ª± ƒëo√°n
  ‚îî‚îÄ requirements.txt
  ```

- Tham kh·∫£o source [t·∫°i ƒë√¢y](https://github.com/sy-duc/house_price_ai).

### 4Ô∏è‚É£ Import & t·∫°o d·ªØ li·ªáu

#### ‚ù∂ T·∫°o d·ªØ li·ªáu

- ƒê·ªÉ hi·ªÉu PyTorch, ch√∫ng ta th∆∞·ªùng s·∫Ω t·∫°o d·ªØ li·ªáu gi·∫£ l·∫≠p ƒë·ªÉ d·ªÖ ki·ªÉm so√°t ho√†n to√†n logic, tr√°nh r·ªëi b·ªüi preprocessing s·ªõm.

  - üëâ Khi hi·ªÉu r·ªìi s·∫Ω thay b·∫±ng d·ªØ li·ªáu th·∫≠t (CSV, DB, API).

- `data.py`:

  ```python
  def generate_house_data(num_samples=1000):
      """
      T·∫°o d·ªØ li·ªáu gi·∫£ l·∫≠p cho b√†i to√°n d·ª± ƒëo√°n gi√° nh√†
      G·ªìm 1000 m·∫´u d·ªØ li·ªáu
      Trong th·ª±c t·∫ø, h√†m n√†y s·∫Ω l√† load CSV / query DB / call API
      """

      # Gi·ªØ cho d·ªØ li·ªáu random lu√¥n gi·ªëng nhau m·ªói l·∫ßn ch·∫°y code
      np.random.seed(42)  # 42 kh√¥ng c√≥ √Ω nghƒ©a k·ªπ thu·∫≠t ƒë·∫∑c bi·ªát ‚Äî n√≥ l√† m·ªôt ‚Äúcon s·ªë truy·ªÅn th·ªëng‚Äù trong gi·ªõi l·∫≠p tr√¨nh

      # Di·ªán t√≠ch (m¬≤): s·ªë th·ª±c t·ª´ 30 -> 200
      area = np.random.uniform(30, 200, num_samples)
      # S·ªë ph√≤ng ng·ªß: s·ªë nguy√™n t·ª´ 1 -> 5
      bedrooms = np.random.randint(1, 6, num_samples)
      # Kho·∫£ng c√°ch t·ªõi trung t√¢m (km): s·ªë th·ª±c t·ª´ 1 -> 20
      distance = np.random.uniform(1, 20, num_samples)

      # C√¥ng th·ª©c gi√° (ch·ªâ gi·∫£ ƒë·ªãnh ƒë·ªÉ t·∫°o d·ªØ li·ªáu, AI kh√¥ng bi·∫øt c√¥ng th·ª©c n√†y)
      price = (
          area * 5000                               # Nh√† to ‚Üí gi√° cao
          + bedrooms * 100000                       # Nhi·ªÅu ph√≤ng ‚Üí ƒë·∫Øt
          - distance * 30000                        # Xa trung t√¢m ‚Üí r·∫ª
          + np.random.normal(0, 50000, num_samples) # Noise (b·ªüi th·ª±c t·∫ø s·∫Ω kh√¥ng ho√†n h·∫£o. Kh√¥ng c√≥ noise ‚Üí model h·ªçc qu√° d·ªÖ, kh√¥ng th·ª±c t·∫ø)
      )

      # Gom feature th√†nh ma tr·∫≠n X - d·∫°ng AI c√≥ th·ªÉ d√πng do AI kh√¥ng hi·ªÉu bi·∫øn r·ªùi r·∫°c
      X = np.column_stack((area, bedrooms, distance))  # M·ªói d√≤ng = 1 cƒÉn nh√†
      y = price # Nh√£n (gi√° nh√†)

      return X, y
  ```

#### ‚ù∑ Chu·∫©n h√≥a d·ªØ li·ªáu (Normalize)

- T∆∞∆°ng ƒë∆∞∆°ng b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω (preprocessing).

- V√≠ d·ª•:

  ```
  Area (m¬≤):      [50, 120, 200]
  Bedrooms:      [1, 3, 5]
  Distance (km): [2, 10, 18]
  ```

  - üëâ Scale kh√°c nhau r·∫•t l·ªõn, Gradient h·ªçc:
    - ‚úß Area √°p ƒë·∫£o
    - ‚úß Bedrooms g·∫ßn nh∆∞ b·ªã ‚Äúb·ªè qua‚Äù

- ‚úîÔ∏è Normalize = ƒë∆∞a v·ªÅ c√πng thang ƒëo:

  | Feature  | Tr∆∞·ªõc    | Sau          |
  | -------- | -------- | ------------ |
  | Area     | 50 ‚Üí 200 | -1.19 ‚Üí 1.25 |
  | Bedrooms | 1 ‚Üí 5    | -1.22 ‚Üí 1.22 |
  | Distance | 2 ‚Üí 18   | -1.15 ‚Üí 1.15 |

  - üëâ Model h·ªçc c√¥ng b·∫±ng h∆°n.

- ‚ö†Ô∏è C·∫ßn chu·∫©n h√≥a d·ªØ li·ªáu cho c·∫£ input v√† output (price).

- `data.py`:

  ```python
  def normalize_features(X):
      mean = X.mean(axis=0) # T√≠nh trung b√¨nh
      std = X.std(axis=0)   # T√≠nh ƒë·ªô l·ªách chu·∫©n (c√°c gi√° tr·ªã c√°ch xa trung b√¨nh bao nhi√™u)

      X_norm = (X - mean) / std
      return X_norm, mean, std

  def normalize_target(y):
      mean = y.mean()
      std = y.std()
      y_norm = (y - mean) / std
      return y_norm, mean, std
  ```

#### ‚ù∏ T·∫°o Dataset

- `data.py`:

  ```python
  class HousePriceDataset(Dataset):
      def __init__(self, X, y):
          self.X = torch.tensor(X, dtype=torch.float32)  # Chuy·ªÉn numpy ‚Üí torch.Tensor
          self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)  # view(-1, 1) ƒë·ªÉ ƒë·∫£m b·∫£o shape label kh·ªõp output, tr√°nh l·ªói

      def __len__(self):
          return len(self.X)

      def __getitem__(self, idx):
          return self.X[idx], self.y[idx]
  ```

### 5Ô∏è‚É£ ƒê·ªãnh nghƒ©a Model

- Ch√∫ng ta c·∫ßn k·∫ø th·ª´a `nn.Module` ƒë·ªÉ PyTorch coi ƒë√¢y l√† model.

- `model.py`:

  ```python
  import torch.nn as nn  # Neural Network module

  class HousePriceModel(nn.Module):
      def __init__(self, input_dim):  # input_dim - s·ªë feature ƒë·∫ßu v√†o (trong b√†i to√°n n√†y l√† 3 - area, bedrooms, distance)
          super().__init__()
          self.linear = nn.Linear(input_dim, 1)  # Neural Network v·ªõi 1 layer (Linear Regression)

      def forward(self, x):
          return self.linear(x)
  ```

### 6Ô∏è‚É£ Training Loop

- ƒê√¢y l√† n∆°i AI "h·ªçc".

#### ‚ù∂ Chu·∫©n b·ªã d·ªØ li·ªáu

- `train.py`:

  ```python
  # Chu·∫©n b·ªã d·ªØ li·ªáu
  X, y = generate_house_data(1000)
  X_norm, mean, std = normalize_features(X)
  y_norm, y_mean, y_std = normalize_target(y)

  # T·∫°o dataset
  dataset = HousePriceDataset(X_norm, y_norm)
  # T·∫°o DataLoader ƒë·ªÉ d·ªÖ d√†ng l·∫•y batch d·ªØ li·ªáu
  dataloader = DataLoader(dataset, batch_size=32, shuffle=True) # Kh√¥ng h·ªçc 1000 m·∫´u c√πng l√∫c m√† h·ªçc t·ª´ng mini-batch (shuffle=True tr√°nh model h·ªçc theo th·ª© t·ª±)
  ```

- ‚ú¶ Batch size ·∫£nh h∆∞·ªüng ƒë·∫øn c√°i g√¨?

  | Batch size         | ·∫¢nh h∆∞·ªüng              |
  | ------------------ | ---------------------- |
  | Nh·ªè (8,16)         | H·ªçc ch·∫≠m, noisy        |
  | Trung b√¨nh (32,64) | ·ªîn ƒë·ªãnh, ph·ªï bi·∫øn      |
  | L·ªõn (256+)         | Nhanh nh∆∞ng d·ªÖ overfit |

- ‚ú¶ Batch size trong AI th·ª±c t·∫ø ph·ªï bi·∫øn:

  | H·ªá th·ªëng          | Batch  |
  | ----------------- | ------ |
  | OCR realtime      | 1‚Äì8    |
  | Chatbot embedding | 32‚Äì128 |
  | Vision training   | 32‚Äì64  |
  | Fine-tune LLM     | 1‚Äì4    |

#### ‚ù∑ Kh·ªüi t·∫°o model

- `train.py`:

  ```python
  # Kh·ªüi t·∫°o model v·ªõi 3 feature
  model = HousePriceModel(input_dim=3)
  ```

#### ‚ù∏ Loss Function

- `train.py`:

  ```python
  # Thi·∫øt l·∫≠p h√†m m·∫•t m√°t (Loss Function) v√† optimizer
  criterion = torch.nn.MSELoss()
  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
  ```

  - `lr=001`: learning rate - M·ªói l·∫ßn update weight, ch·ªâ thay ƒë·ªïi 0.1% theo h∆∞·ªõng gi·∫£m loss.

  - Learning rate qu√° l·ªõn l√†m cho Loss nh·∫£y lo·∫°n.

  - Learning rate qu√° nh·ªè l√†m cho Loss gi·∫£m r·∫•t ch·∫≠m v√† train r·∫•t l√¢u.

#### ‚ùπ Training Loop

- `train.py`:

```python
epochs = 100  # S·ªë epoch ƒë·ªÉ hu·∫•n luy·ªán (1 epoch = h·ªçc h·∫øt dataset 1 l·∫ßn)

for epoch in range(epochs):
    total_loss = 0

    # L·∫∑p qua t·ª´ng batch
    for X_batch, y_batch in dataloader:
        # Forward pass (d·ª± ƒëo√°n)
        preds = model(X_batch)
        # T√≠nh loss (so s√°nh v·ªõi gi√° th·∫≠t)
        loss = criterion(preds, y_batch)
        # Zero gradients tr∆∞·ªõc khi backward (PyTorch c·ªông d·ªìn gradient ‚Üí n·∫øu kh√¥ng reset ‚Üí gradient sai)
        optimizer.zero_grad()
        # Backward pass (t√≠nh gradient)
        loss.backward()
        # Weight thay ƒë·ªïi ‚Üí model th√¥ng minh h∆°n
        optimizer.step()

        total_loss += loss.item()

    # In k·∫øt qu·∫£: Loss gi·∫£m = model h·ªçc ƒë∆∞·ª£c
    print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}")
```

#### ‚ù∫ L∆∞u model v√† th√¥ng tin chu·∫©n h√≥a

- `train.py`:

  ```python
  torch.save({
      "model_state": model.state_dict(),
      "X_mean": mean,
      "X_std": std,
      "y_mean": y_mean,
      "y_std": y_std
  }, "model.pth")
  ```

### 7Ô∏è‚É£ D·ª± ƒëo√°n

#### ‚ù∂ Load checkpoint an to√†n

- Load model ƒë√£ train v√† c√°c th√¥ng tin chu·∫©n h√≥a d·ªØ li·ªáu ƒë√£ l∆∞u tr∆∞·ªõc ƒë√≥:

- `predict.py`:

  ```python
  checkpoint = torch.load("model.pth", weights_only=False)

  model_state = checkpoint["model_state"]
  X_mean = checkpoint["X_mean"]
  X_std = checkpoint["X_std"]
  y_mean = checkpoint["y_mean"]
  y_std = checkpoint["y_std"]
  ```

#### ‚ù∑ Kh·ªüi t·∫°o model ƒë√£ h·ªçc

- `predict.py`:

  ```python
  model = HousePriceModel(input_dim=3)
  ```

#### ‚ù∏ Load tr·ªçng s·ªë ƒë√£ h·ªçc

- `predict.py`:

  ```python
  model.load_state_dict(model_state)
  ```

#### ‚ùπ Chuy·ªÉn sang ch·∫ø ƒë·ªô ƒë√°nh gi√°

- `predict.py`:

  ```python
  model.eval()
  ```

#### ‚ù∫ Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o

- Nh·∫≠p d·ªØ li·ªáu m·ªõi (ch∆∞a t·ª´ng th·∫•y) ƒë·ªÉ model d·ª± ƒëo√°n k·∫øt qu·∫£ gi√° nh√†.

- `predict.py`:

  ```python
  # T·∫°o m·ªôt m·∫´u d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n (1 cƒÉn nh√†: 120 m¬≤ + 3 ph√≤ng + c√°ch trung t√¢m 5 km)
  sample = torch.tensor([[120, 3, 5]], dtype=torch.float32)

  # Normalize input gi·ªëng l√∫c train
  sample_norm = (sample - X_mean) / X_std
  sample_tensor = torch.tensor(sample_norm, dtype=torch.float32)
  ```

#### ‚ùª Forward ‚Äì AI d·ª± ƒëo√°n

- ‚ö†Ô∏è Khi predict ph·∫£i d√πng c√πng mean & std ƒë√£ chu·∫©n h√≥a tr∆∞·ªõc ƒë√≥.

- `predict.py`:

  ```python
  with torch.no_grad():  # T·∫Øt gradient khi predict
    # Forward ‚Äì AI d·ª± ƒëo√°n
    y_pred_norm = model(sample_tensor)

  # Denormalize output ‚Üí gi√° th·∫≠t
  price = y_pred_norm.item() * y_std + y_mean

  # In k·∫øt qu·∫£ ra d·∫°ng s·ªë
  print(f"Predicted price: {price:,.0f} VND")
  ```

### 7Ô∏è‚É£ Ch·∫°y ch∆∞∆°ng tr√¨nh d·ª± ƒëo√°n

#### ‚ù∂ Ch·∫°y TRAIN t·∫°o model d·ª± ƒëo√°n gi√° nh√†

- ```bash
  python train.py
  ```

  - üëâ Sinh ra file `model.pth`

#### ‚ù∑ Ch·∫°y PREDICT (d·ª± ƒëo√°n)

- ```bash
  python predict.py
  ```

- ·ªû nh·ªØng l·∫ßn ch·∫°y d·ª± ƒëo√°n gi√° nh√† sau s·∫Ω kh√¥ng c·∫ßn ch·∫°y train n·ªØa (tr·ª´ khi mu·ªën train l·∫°i).

### ‚ö†Ô∏è Quan tr·ªçng:

- Trong b√†i ƒëo√°n v·ª´a l√†m ch·ªâ l√† Linear Regression vi·∫øt b·∫±ng PyTorch, n√≥ ƒëang ph√π h·ª£p v·ªõi ho√†n c·∫£nh b√†i to√°n i·ªán t·∫°i:

  - D·ªØ li·ªáu √≠t (di·ªán t√≠ch, s·ªë ph√≤ng, kho·∫£ng c√°ch)
  - Quan h·ªá g·∫ßn tuy·∫øn t√≠nh
  - üëâ Nhi·ªÅu h·ªá th·ªëng production c≈©ng ch·ªâ c·∫ßn c√≥ v·∫≠y.

- Tuy nhi√™n, th·ª±c t·∫ø s·∫Ω c√≥ nh·ªØng b√†i to√°n d·ª± ƒëo√°n v·ªõi data nhi·ªÅu, ph·ª• thu·ªôc ph·ª©c t·∫°p (quan h·ªá phi tuy·∫øn):

  - V√≠ d·ª• gi√° nh√† ph·ª• thu·ªôc th√™m c·∫£ tu·ªïi th·ªç, n·ªôi th·∫•t, v.v.
  - üëâ Linear kh√¥ng bi·ªÉu di·ªÖn ƒë∆∞·ª£c ‚Äúlogic ƒëi·ªÅu ki·ªán‚Äù, v√† s·∫Ω c·∫ßn ƒë·∫øn Deep Learning v·ªõi c√°c hidden layers (MLP ‚Äì Multi-Layer Perceptron):

    ```
    x ‚Üí Linear ‚Üí ReLU ‚Üí Linear ‚Üí ReLU ‚Üí Linear ‚Üí y
    ```

<a name="3"></a>

## üìå 3. B√†i to√°n Multi-Layer Perceptron (Binary Classification)

- B√†i to√°n: Giao d·ªãch b√¨nh th∆∞·ªùng / b·∫•t th∆∞·ªùng

### 1Ô∏è‚É£ Ph√¢n t√≠ch b√†i to√°n

- Input: Th√¥ng tin giao d·ªãch
- Output: B√¨nh th∆∞·ªùng / B·∫•t th∆∞·ªùng

- ‚ö†Ô∏è **L∆∞u √Ω**:

  - ‚úß Model s·∫Ω KH√îNG tr·∫£ v·ªÅ tr·ª±c ti·∫øp 0 (giao d·ªãch b√¨nh th∆∞·ªùng) v√† 1 (giao d·ªãch b·∫•t th∆∞·ªùng).
  - ‚úß Model s·∫Ω tr·∫£ v·ªÅ 1 s·ªë th·ª±c (g·ªçi l√† **logit**) ‚Üí sau ƒë√≥ qua **Sigmoid** (h√†m Logistic - ƒë∆∞·ªùng ch·ªØ S) ‚Üí **x√°c su·∫•t**.
  - ‚úß V√≠ d·ª•:
    | Logit | Sigmoid | K·∫øt lu·∫≠n |
    | ----- | ------- | ----------- |
    | 2.3 | 0.91 | B·∫•t th∆∞·ªùng |
    | -1.2 | 0.23 | B√¨nh th∆∞·ªùng |

    ```
    prob >= 0.5 ‚Üí b·∫•t th∆∞·ªùng
    ```

### 2Ô∏è‚É£ D·ªØ li·ªáu gi·∫£ l·∫≠p

- M·ªói giao d·ªãch c√≥ c√°c ƒë·∫∑c tr∆∞ng (feature).

  - V√≠ d·ª•:
    | Feature | √ù nghƒ©a |
    | -------------- | ------------------------- |
    | amount | S·ªë ti·ªÅn |
    | hour | Gi·ªù giao d·ªãch (0‚Äì23) |
    | location_score | M·ª©c ƒë·ªô l·∫° c·ªßa v·ªã tr√≠ |
    | device_score | M·ª©c ƒë·ªô l·∫° c·ªßa thi·∫øt b·ªã |
    | freq_24h | S·ªë giao d·ªãch 24h g·∫ßn nh·∫•t |

- Trong b√†i n√†y ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng dataset m·∫´u c√≥ r·∫•t nhi·ªÅu feature.
  - üëâ Tuy nhi√™n, b·∫°n c≈©ng kh√¥ng c·∫ßn thi·∫øt hi·ªÉu √Ω nghƒ©a t·ª´ng feature nh∆∞ v·∫≠y, b·ªüi sau c√πng th√¨ Neural Network ch·ªâ c·∫ßn s·ªë, kh√¥ng c·∫ßn bi·∫øt ƒë√≥ l√† g√¨.

### 3Ô∏è‚É£ Import d·ªØ li·ªáu

- Ch√∫ng ta s·∫Ω d√πng Dataset c√≥ s·∫µn do [Kaggle](https://www.kaggle.com) cung c·∫•p.

#### ‚ù∂ T·∫£i Dataset m·∫´u

- T·∫£i dataset Credit Card Fraud Detection [t·∫°i ƒë√¢y](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).

- Gi·∫£i n√©n ra file `creditcard.csv` v√† ƒë·∫∑t v√†o project.

#### ‚ù∑ Chia train / validation

- H√£y ƒë√°nh gi√° l·∫°i Dataset m·∫´u ch√∫ng ta s·ª≠ d·ª•ng:

  - ~99.8% l√† c√°c data c√≥ class = 0 (giao d·ªãch b√¨nh th∆∞·ªùng)
  - ~0.2% l√† c√°c data c√≥ class = 1 (fraud - giao d·ªãch b·∫•t th∆∞·ªùng)
  - üëâ M·∫•t c√¢n b·∫±ng nghi√™m tr·ªçng.

- ‚ùì Chuy·ªán g√¨ x·∫£y ra n·∫øu KH√îNG chia train / validation?

  - Gi·∫£ s·ª≠ 1000 giao d·ªãch:

    - ‚úß 998 normal
    - ‚úß 2 fraud

  - Chia train / validation = 80/20:

    - ‚úß Train: 798 normal + 2 fraud
    - ‚úß Val: 200 normal + 0 fraud ‚ùå

  - üëâ ƒê√°nh gi√° l√† **v√¥ nghƒ©a** do validation kh√¥ng c√≥ fraud n√†o.

- V·ªõi AI c·∫£nh b√°o, validation tr·ªü n√™n v√¥ c√πng quan tr·ªçng:

  - Sai 1 giao d·ªãch = h·∫≠u qu·∫£ l·ªõn.

- ‚úÖ Do v·∫≠y, ch√∫ng ta c·∫ßn gi·ªØ t·ª∑ l·ªá fraud gi·ªëng nhau ·ªü train & val.

- `prepare_data.py`:

  ```python
  import pandas as pd
  from sklearn.model_selection import train_test_split

  df = pd.read_csv("data/creditcard.csv")

  train_df, temp_df = train_test_split(
      df,
      test_size=0.3,
      random_state=42,
      stratify=df["Class"]
  )

  val_df, test_df = train_test_split(
      temp_df,
      test_size=0.5,
      random_state=42,
      stratify=temp_df["Class"]
  )

  train_df.to_csv("data/train.csv", index=False)
  val_df.to_csv("data/val.csv", index=False)
  test_df.to_csv("data/test.csv", index=False)
  ```

  - ‚úß ·ªû ƒë√¢y ch√∫ng ta chia 70% d·ªØ li·ªáu cho training, 30% cho validation v√† test (trong 30% n√†y chia 50:50 cho validation v√† test).
  - ‚úß D·ªØ li·ªáu sau khi chia ƒë∆∞·ª£c l∆∞u v√†o 3 file `.csv` ri√™ng bi·ªát.
  - ‚úß `stratify = df["Class"] (y)` gi·ªØ t·ª∑ l·ªá fraud gi·ªëng nhau ·ªü train & val.

#### ‚ù∏ Chu·∫©n h√≥a d·ªØ li·ªáu

- N·∫øu quan s√°t Dataset m·∫´u s·∫Ω th·∫•y:

  - V1..V28 ‚Üí gi√° tr·ªã quanh 0.
  - Amount ‚Üí c√≥ th·ªÉ l√™n t·ªõi v√†i ch·ª•c ngh√¨n.

- ‚ùå N·∫øu kh√¥ng chu·∫©n h√≥a:

  - Neural Network h·ªçc l·ªách.
  - Gradient kh√≥ h·ªôi t·ª•.

- ‚úîÔ∏è Ch√∫ng ta s·∫Ω d√πng c√¥ng c·ª• h·ªó tr·ª£ chu·∫©n h√≥a ph·ªï bi·∫øn `StandardScaler`.

- `fit_scaler.py`:

  ```python
  import pandas as pd
  from sklearn.preprocessing import StandardScaler
  import joblib

  # ƒê·ªçc d·ªØ li·ªáu hu·∫•n luy·ªán
  df = pd.read_csv("data/train.csv")
  X = df.drop(columns=["Class", "Time"])

  # Chu·∫©n h√≥a d·ªØ li·ªáu
  scaler = StandardScaler()
  scaler.fit(X)

  # L∆∞u tr·ªØ scaler
  joblib.dump(scaler, "artifacts/scaler.pkl")
  ```

  - T·∫°m th·ªùi kh√¥ng d√πng c·ªôt `Time` do ƒë√¢y l√† s·ªë gi√¢y k·ªÉ t·ª´ giao d·ªãch ƒë·∫ßu ti√™n, kh√¥ng mang √Ω nghƒ©a r√µ r√†ng cho b√†i to√°n anomaly ‚Üí d·ªÖ g√¢y nhi·ªÖu.

  - C·ªôt `Class` d√πng cho label (nh√£n) ‚Üí t·ªïng c√≤n 29 feature.

- ‚ö†Ô∏è KH√îNG chu·∫©n h√≥a `y` trong b√†i to√°n Classification b·ªüi `y` mang √Ω nghƒ©a logic (0 ho·∫∑c 1) ch·ª© kh√¥ng ph·∫£i gi√° tr·ªã ƒëo l∆∞·ªùng.

### 4Ô∏è‚É£ T·∫°o PyTorch Dataset

- Khi training, validation v√† test th√¨ ƒë·ªÅu c·∫ßn t·∫°o Dataset

  - üëâ Ta s·∫Ω truy·ªÅn `csv_path` ƒë·∫øn file d·ªØ li·ªáu m·∫´u ƒë√£ chia ban ƒë·∫ßu.

- `dataset.py`:

  ```python
  import pandas as pd
  import torch
  from torch.utils.data import Dataset

  class FraudDataset(Dataset):
      def __init__(self, csv_path, scaler=None):
          df = pd.read_csv(csv_path)

          X_df = df.drop(columns=["Class", "Time"])
          y = df["Class"].values

          # Chu·∫©n h√≥a d·ªØ li·ªáu n·∫øu scaler ƒë∆∞·ª£c cung c·∫•p
          if scaler is not None:
              # √Åp d·ª•ng chu·∫©n h√≥a (mean, std) ƒë√£ h·ªçc
              X = scaler.transform(X_df)
          else:
              X = X_df.values

          self.X = torch.tensor(X, dtype=torch.float32)
          self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)

      def __len__(self):
          return len(self.y)

      def __getitem__(self, idx):
          return self.X[idx], self.y[idx]
  ```

### 5Ô∏è‚É£ ƒê·ªãnh nghƒ©a Model

- `model.py`:

  ```python
  import torch.nn as nn

  class FraudMLP(nn.Module):
      def __init__(self, input_dim):
          super().__init__()

          self.model = nn.Sequential(
              nn.Linear(input_dim, 64),
              nn.ReLU(),
              nn.Linear(64, 32),
              nn.ReLU(),
              nn.Linear(32, 1)
          )

      def forward(self, x):
          return self.model(x)
  ```

- C·∫•u tr√∫c MLP c∆° b·∫£n:

  ```scss
  Input (29)
     ‚Üì
  Linear(29 ‚Üí 64)
     ‚Üì
  ReLU
     ‚Üì
  Linear(64 ‚Üí 32)
     ‚Üì
  ReLU
     ‚Üì
  Linear(32 ‚Üí 1)
     ‚Üì
  Logits
  ```

  - `Linear(29 ‚Üí 64)`: Layer 1 - l·∫•y 29 s·ªë ƒë·∫ßu v√†o t·∫°o ra 64 ƒë·∫∑c tr∆∞ng m·ªõi.

    - V√≠ d·ª•:
      - Feature 1: ‚Äúm·∫´u giao d·ªãch l·∫° ban ƒë√™m‚Äù
      - Feature 2: ‚Äús·ªë ti·ªÅn cao + v·ªã tr√≠ b·∫•t th∆∞·ªùng‚Äù
      - v.v.

  - `Linear(64 ‚Üí 32)`: Layer 2 - gom 64 ƒë·∫∑c tr∆∞ng trung gian, ch·∫Øt l·ªçc th√†nh 32 ƒë·∫∑c tr∆∞ng tr·ª´u t∆∞·ª£ng h∆°n.

    - N√¥m na n·∫øu coi Layer 1 l√† c√°c pattern nh·ªè th√¨ Layer 2 cho ch√∫ng ta th·∫•y c√°c d·∫•u hi·ªáu gian l·∫≠n, b·∫•t th∆∞·ªùng.

  - `Linear(32 ‚Üí 1)`: Output layer - 1 con s·ªë duy nh·∫•t th·ªÉ hi·ªán ƒë·ªô tin (ch∆∞a ph·∫£i x√°c su·∫•t m√† m·ªõi ch·ªâ l√† **logit**) r·∫±ng giao d·ªãch n√†y l√† fraud.

  - `ReLU`: T·∫°o phi tuy·∫øn, cho ph√©p model h·ªçc quan h·ªá ph·ª©c t·∫°p.
    - V√≠ d·ª• mu·ªën ph√°t hi·ªán ‚ÄúGiao d·ªãch ban ƒë√™m v√† s·ªë ti·ªÅn l·ªõn th√¨ ƒë√°ng nghi‚Äù:
      - N·∫øu ban ng√†y ‚Üí gi√° tr·ªã √¢m ‚Üí ReLU = 0 ‚Üí kh√¥ng quan t√¢m
      - N·∫øu ban ƒë√™m ‚Üí gi√° tr·ªã d∆∞∆°ng ‚Üí ReLU gi·ªØ l·∫°i ‚Üí k√≠ch ho·∫°t
      - üëâ N·∫øu kh√¥ng c√≥ `ReLU`: tr·ªùi s√°ng hay t·ªëi kh√¥ng quan t√¢m ‚Üí ban ng√†y v·∫´n b·ªã ƒë√°ng nghi

- ‚ö†Ô∏è **L∆∞u √Ω**:
  - C√°c con s·ªë 64, 32 l√† do kinh nghi·ªám + th·ª≠ nghi·ªám, kh√¥ng c√≥ c√¥ng th·ª©c ch√≠nh x√°c.

### 6Ô∏è‚É£ Training Loop

- Nh√¨n chung, khung Training Loop trong b√†i to√°n n√†y c≈©ng t∆∞∆°ng t·ª± b√†i to√°n D·ª± ƒëo√°n gi√° nh√†.

  - ƒêi·ªÉm kh√°c bi·ªát l√† s·ª≠ d·ª•ng h√†m m·∫•t m√°t (Loss Function) `BCEWithLogitsLoss` gi√∫p t·ª± ƒë·ªông √°p d·ª•ng Sigmoid:

    ```
    BCEWithLogitsLoss = Sigmoid(logit) + BCELoss
    ```

- `train.py`:

  ```python
  import torch
  import joblib
  from torch.utils.data import DataLoader
  from torch import nn, optim

  from model import FraudMLP
  from dataset import FraudDataset

  # Load scaler
  scaler = joblib.load("artifacts/scaler.pkl")

  # T·∫°o Dataset
  train_ds = FraudDataset("data/train.csv", scaler)

  # T·∫°o DataLoader
  train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)

  # Kh·ªüi t·∫°o model, loss function v√† optimizer
  model = FraudMLP(29).to("cpu")
  criterion = nn.BCEWithLogitsLoss()
  optimizer = optim.Adam(model.parameters(), lr=0.001)

  # Hu·∫•n luy·ªán m√¥ h√¨nh
  EPOCHS = 10
  for epoch in range(EPOCHS):
      model.train()
      total_loss = 0

      for X, y in train_loader:
          X, y = X.to("cpu"), y.to("cpu").view(-1, 1)

          optimizer.zero_grad()
          logits = model(X)
          loss = criterion(logits, y)
          loss.backward()
          optimizer.step()

          total_loss += loss.item()

      avg_loss = total_loss / len(train_loader)
      print(f"Epoch {epoch+1}, loss={avg_loss:.4f}")

  torch.save(model.state_dict(), "artifacts/model.pth")
  ```

### 7Ô∏è‚É£ Validation & Metrics

- ‚ùå Training loss ch·ªâ cho bi·∫øt model nh·ªõ data train t·ªët t·ªõi ƒë√¢u, kh√¥ng gi√∫p t·ªïng qu√°t h√≥a model.

  - B·ªüi th·ª±c t·∫ø v·ªõi data m√† model ch∆∞a t·ª´ng th·∫•y, output c√≥ th·ªÉ fail.

- ‚úîÔ∏è Validation gi√∫p:

  - ‚ú¶ Ki·ªÉm tra kh·∫£ nƒÉng t·ªïng qu√°t:

    - Model h·ªçc c√≥ √°p d·ª•ng ƒë∆∞·ª£c cho d·ªØ li·ªáu m·ªõi kh√¥ng?

  - ‚ú¶ Quy·∫øt ƒë·ªãnh d·ª´ng train:

    ```
    Epoch 10: Val loss nh·ªè nh·∫•t ‚Üí gi·ªØ model
    Epoch 11+: Val loss tƒÉng ‚Üí stop
    ```

  - ‚ú¶ So s√°nh model / hyperparameter:

    ```
    LR = 0.01 ‚Üí val loss = 0.42
    LR = 0.001 ‚Üí val loss = 0.31 ‚úÖ
    ```

    - üëâ Ch·ªçn c√°i t·ªët tr√™n validation, kh√¥ng ph·∫£i train.

  - ‚ú¶ Ch·ªçn threshold / metric ph√π h·ª£p:

    - ‚úß V·ªõi l∆∞·ª£ng Dataset m·∫´u 99% l√† normal, 1% l√† fraud:

      - V√≠ d·ª• output:
        | Giao d·ªãch | X√°c su·∫•t fraud |
        | ---------- | -------------- |
        | Fraud th·∫≠t | 0.42 |
        | Fraud th·∫≠t | 0.37 |
        | Normal | 0.05 |
      - üëâ N·∫øu threshold = 0.5 s·∫Ω kh√¥ng b·∫Øt ƒë∆∞·ª£c fraud n√†o.

    - ‚úß Ch√∫ng ta s·∫Ω c·∫ßn:

      - ‚ûÄ Precision

        ```
        Trong nh·ªØng c√°i m√¨nh b√°o fraud ‚Üí bao nhi√™u c√°i l√† fraud th·∫≠t
        ```

        - üëâ Precision cao ‚Üí √≠t b√°o nh·∫ßm

      - ‚ûÅ Recall

      ```
      Trong t·∫•t c·∫£ fraud th·∫≠t ‚Üí m√¨nh b·∫Øt ƒë∆∞·ª£c bao nhi√™u
      ```

      - üëâ Recall th·∫•p ‚Üí b·ªè s√≥t gian l·∫≠n

    - üî• **T√≥m l·∫°i**:

      - ‚úß Kh√¥ng c√≥ threshold ‚Äúƒë√∫ng‚Äù, ch·ªâ c√≥ threshold ph√π h·ª£p m·ª•c ti√™u kinh doanh.

      - ‚úß Ch·ªçn threshold: ∆Øu ti√™n Recall (Recall ‚â• 85%) ho·∫∑c c√¢n b·∫±ng Precision / Recall ho·∫∑c c√¢n b·∫±ng chi ph√≠ ti·ªÅn b·∫°c:
        - V√≠ d·ª•:
          - B·ªè s√≥t 1 fraud = m·∫•t 1.000$
          - B√°o nh·∫ßm 1 giao d·ªãch = t·ªën 5$
          - üëâ Ta ch·ªçn threshold b√°o nh·∫ßm c√≤n h∆°n b·ªè s√≥t.

- ‚ö†Ô∏è **Validation loop ch·ªâ forward + ƒëo metric, KH√îNG backward.**

- `validation.py`:

  ```python
  import torch
  import joblib
  import numpy as np
  import json
  from sklearn.metrics import recall_score
  from torch.utils.data import DataLoader

  from dataset import FraudDataset
  from model import FraudMLP

  # Load scaler
  scaler = joblib.load("artifacts/scaler.pkl")

  # T·∫°o Dataset
  val_ds = FraudDataset("data/val.csv", scaler)

  # T·∫°o DataLoader
  val_loader = DataLoader(val_ds, batch_size=256, shuffle=False)

  # Kh·ªüi t·∫°o model
  model = FraudMLP(29).to("cpu")
  state_dict = torch.load("artifacts/model.pth", weights_only=True)
  model.load_state_dict(state_dict)

  # Chuy·ªÉn ƒë·ªïi model sang ch·∫ø ƒë·ªô ƒë√°nh gi√°
  model.eval()

  all_probs, all_labels = [], []

  with torch.no_grad():
      for X, y in val_loader:
          X, y = X.to("cpu"), y.to("cpu").view(-1, 1)

          logits = model(X)
          probs = torch.sigmoid(logits)

          all_probs.append(probs.detach().cpu().numpy())
          all_labels.append(y.detach().cpu().numpy())

  # G·ªôp t·∫•t c·∫£ c√°c d·ª± ƒëo√°n v√† nh√£n l·∫°i
  probs = np.vstack(all_probs).ravel()
  labels = np.vstack(all_labels).ravel()

  # Kh·ªüi t·∫°o threshold m·∫∑c ƒë·ªãnh ban ƒë·∫ßu
  best_threshold, best_recall = 0.5, 0

  # T√¨m ki·∫øm ng∆∞·ª°ng t·ªët nh·∫•t
  # Qu√©t threshold t·ª´ 0.1 ƒë·∫øn 0.9 v·ªõi step 0.05 ƒë·ªÉ t·ªëi ∆∞u h√≥a
  for t in np.arange(0.1, 0.9, 0.05):
      # D·ª± ƒëo√°n nh√£n
      preds = (probs >= t).astype(int)
      # T√≠nh Recall
      recall = recall_score(labels, preds)
      # Gi·ªØ threshold t·ªët nh·∫•t
      if recall > best_recall:
          best_recall = recall
          best_threshold = t

  # L∆∞u threshold v√† recall t·ªët nh·∫•t v√†o file config.json
  config = {
      "threshold": float(best_threshold),
      "recall": float(best_recall)
  }

  with open("artifacts/config.json", "w") as f:
      json.dump(config, f, indent=2)

  print("Best threshold:", best_threshold)
  ```

### 8Ô∏è‚É£ Test

- ‚ú¶ L√† b∆∞·ªõc ƒë√°nh gi√° cu·ªëi c√πng.

- ‚ú¶ Khi test ph·∫£i d√πng d·ªØ li·ªáu th·ª±c t·∫ø m√† model ch∆∞a t·ª´ng th·∫•y.

  - üëâ Ch√∫ng ta s·ª≠ d·ª•ng d·ªØ li·ªáu test ƒë√£ chia ban ƒë·∫ßu.

- ‚ú¶ Sau b∆∞·ªõc validation, ch√∫ng ta ƒë√£ kh√≥a model + threshold.

  - üëâ Giai ƒëo·∫°n test s·∫Ω √°p d·ª•ng threshold ƒë√£ ch·ªçn ƒë·ªÉ ki·ªÉm ch·ª©ng vi·ªác n·∫øu ƒë∆∞a model ra production th√¨ n√≥ s·∫Ω ho·∫°t ƒë·ªông ra sao.

- ‚ú¶ ƒê·ªÉ ki·ªÉm ch·ª©ng k·∫øt qu·∫£ test:

  - ‚úß C√≥ b·ªè s√≥t fraud nhi·ªÅu kh√¥ng?
  - ‚úß B√°o nh·∫ßm bao nhi√™u?
  - üëâ Log b√°o c√°o test l√† kh√¢u quan tr·ªçng v√† b·∫Øt bu·ªôc.

- `test.py`:

  ```python
  import json
  import torch
  import joblib
  import numpy as np
  from torch.utils.data import DataLoader
  from sklearn.metrics import classification_report, roc_auc_score

  from model import FraudMLP
  from dataset import FraudDataset

  # Load scaler
  scaler = joblib.load("artifacts/scaler.pkl")

  # T·∫°o Dataset
  test_ds = FraudDataset("data/test.csv", scaler)

  # T·∫°o DataLoader
  test_loader = DataLoader(test_ds, batch_size=256, shuffle=False)

  # Kh·ªüi t·∫°o model
  model = FraudMLP(29).to("cpu")
  state_dict = torch.load("artifacts/model.pth", weights_only=True)
  model.load_state_dict(state_dict)

  # Chuy·ªÉn ƒë·ªïi model sang ch·∫ø ƒë·ªô ƒë√°nh gi√°
  model.eval()

  # T√¨m ng∆∞·ª°ng t·ªëi ∆∞u h·ªçc t·ª´ validation
  with open("artifacts/config.json") as f:
      threshold = json.load(f)["threshold"]

  all_probs, all_labels = [], []

  with torch.no_grad():
      for X, y in test_loader:
          X, y = X.to("cpu"), y.to("cpu").view(-1, 1)
          probs = torch.sigmoid(model(X))
          all_probs.append(probs.numpy())
          all_labels.append(y.numpy())

  probs = np.vstack(all_probs).ravel()
  labels = np.vstack(all_labels).ravel()

  # D·ª± ƒëo√°n nh√£n
  preds = (probs >= threshold).astype(int)

  print(classification_report(labels, preds))
  print("AUC:", roc_auc_score(labels, probs))
  ```

- ‚ú¶ V√≠ d·ª• log k·∫øt qu·∫£ test:

  - **‚ûÄ `classification_report` ‚Äì ƒê·ªçc T·ª™NG D√íNG**

    ```markdown
                      precision    recall  f1-score   support

                0.0       1.00      1.00      1.00      42648
                1.0       0.77      0.84      0.80         74

          accuracy                            1.00      42722
          macro avg       0.88      0.92      0.90      42722
        weighted avg      1.00      1.00      1.00      42722
    ```

    - Ch√∫ng ta s·∫Ω ch·ªâ quan t√¢m d√≤ng `1.0`:
      - `support = 74`: c√≥ 74 giao d·ªãch gian l·∫≠n th·∫≠t tr√™n 42648 giao d·ªãch.
      - `recall = 0.84`: trong 74 giao d·ªãch gian l·∫≠n model b·∫Øt ƒë∆∞·ª£c 84% (‚â• 0.8 l√† T·ªêT).
      - `precision = 0.77`: trong c√°c giao d·ªãch model b·∫Øt gian l·∫≠n, 77% l√† th·∫≠t.
      - `f1-score = 0.80`: trung b√¨nh c·ªßa precision & recall (‚â• 0.75 l√† T·ªêT).

  - **‚ûÅ `roc_auc_score`**
    - L√† x√°c xu·∫•t model ∆∞u ti√™n ƒë√°nh gi√° 1 giao d·ªãch gian l·∫≠n hay kh√¥ng l√™n tr√™n giao d·ªãch b√¨nh th∆∞·ªùng.
    - AUC KH√îNG ph·ª• thu·ªôc threshold.
    - | AUC  | ƒê√°nh gi√° |
      | ---- | -------- |
      | 0.5  | Random   |
      | 0.7  | T·∫°m      |
      | 0.8  | T·ªët      |
      | 0.9  | R·∫•t t·ªët  |
      | 0.97 | Xu·∫•t s·∫Øc |

### 9Ô∏è‚É£ Tri·ªÉn khai inference - ƒê∆∞a model ƒë√£ train ra s·ª≠ d·ª•ng th·∫≠t

#### ‚ûÄ M·ª•c ti√™u

- ƒê∆∞a model ƒë√£ train ra s·ª≠ d·ª•ng th·∫≠t.

- S·ª≠ d·ª•ng ƒë∆∞·ª£c cho c√°c giao d·ªãch realtime ‚Üí c·∫ßn nhanh.

- Kh√¥ng b·ªã l·ªá thu·ªôc code train.

- K·∫øt qu·∫£ gi·ªëng test.

#### ‚ûÅ Chu·∫©n h√≥a artifact c·∫ßn deploy

- Sau khi train xong, deploy KH√îNG c·∫ßn dataset:

  - ‚úîÔ∏è Ch·ªâ c·∫ßn:

    ```
    artifacts/
    ‚îú‚îÄ‚îÄ model.pth        # weight
    ‚îú‚îÄ‚îÄ scaler.pkl       # fitted scaler (chu·∫©n h√≥a d·ªØ li·ªáu)
    ‚îú‚îÄ‚îÄ config.json      # threshold
    ```

  - ‚ùå Kh√¥ng c·∫ßn:
    - `train.py`
    - `validation.py`
    - `creditcard.csv`

#### ‚ûÇ Inference pipeline

- ```
  Raw input
     ‚Üì
  Preprocessing (chu·∫©n h√≥a d·ªØ li·ªáu)
     ‚Üì
  Tensor
     ‚Üì
  Model (logits)
     ‚Üì
  Sigmoid ‚Üí x√°c su·∫•t
     ‚Üì
  Threshold
     ‚Üì
  Decision (Normal / Fraud)
  ```

#### ‚ûÉ Thi·∫øt k·∫ø deploy structure

- ```
  inference/
  ‚îú‚îÄ‚îÄ inference.py
  ‚îú‚îÄ‚îÄ model_loader.py
  ‚îú‚îÄ‚îÄ preprocess.py
  ‚îú‚îÄ‚îÄ schema.py
  ```

- `model_loader.py`:

  ```python
  import torch
  from model import FraudMLP

  def load_model(model_path, input_dim, device):
      model = FraudMLP(input_dim).to(device)
      state_dict = torch.load(model_path, weights_only=True, map_location=device)  #  map_location=device ‚Üí ch·∫°y ƒë∆∞·ª£c c·∫£ CPU/GPU
      model.load_state_dict(state_dict)
      model.eval()
      return model
  ```

- `preprocess.py`:

  ```python
  import pandas as pd
  from inference.schema import FEATURE_ORDER

  def preprocess(features, scaler):
      df = pd.DataFrame([features], columns=FEATURE_ORDER)
      x_scaled = scaler.transform(df)
      return x_scaled
  ```

- `schema.py`:

  ```python
  FEATURE_ORDER = [
      "V1","V2","V3",...,"V28","Amount"
  ]

  def validate_features(features):
      for f in FEATURE_ORDER:
          if f not in features:
              raise ValueError(f"Missing feature: {f}")
  ```

- `inference.py`:

  ```python
  import torch
  import joblib
  import json
  from inference.model_loader import load_model
  from inference.preprocess import preprocess

  DEVICE = "cpu"

  class FraudInference:
      def __init__(self):
          self.scaler = joblib.load("artifacts/scaler.pkl")

          with open("artifacts/config.json") as f:
              self.threshold = json.load(f)["threshold"]

          self.model = load_model(
              "artifacts/model.pth",
              input_dim=29,
              device=DEVICE
          )

      def predict(self, features: dict):
          x_scaled = preprocess(features, self.scaler)
          x_tensor = torch.tensor(x_scaled, dtype=torch.float32).to(DEVICE)

          with torch.no_grad():
              prob = torch.sigmoid(self.model(x_tensor)).item()

          is_fraud = prob >= self.threshold

          return {
              "probability": prob,
              "is_fraud": is_fraud
          }
  ```

- S·ª≠ d·ª•ng:

  ```python
  from inference.inference import FraudInference
  from inference.schema import validate_features

  engine = FraudInference()

  tx = {
      "V1": 1.37855899734127,
      "V2": 1.28938093711056,
      "V3": -5.00424678441137,
      ...
      "V28": 0.186636547522687,
      "Amount": 0.76
  }

  validate_features(tx)
  result = engine.predict(tx)
  print(result)
  ```

#### ‚ûÑ Deploy d·∫°ng g√¨?

- Option 1: Batch (offline):

  ```
  CSV ‚Üí inference.py ‚Üí CSV result
  ```

- Option 2: REST API (ph·ªï bi·∫øn nh·∫•t):

  ```
  Client ‚Üí FastAPI ‚Üí inference.py ‚Üí Response
  ```
